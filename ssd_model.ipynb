{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcui/anaconda3/envs/hcui/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/hcui/anaconda3/envs/hcui/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17329061195881314518\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 2\n",
      "}\n",
      "incarnation: 13782030490837513851\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:85:00.0, compute capability: 3.7\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11330676327\n",
      "locality {\n",
      "  bus_id: 2\n",
      "}\n",
      "incarnation: 7995909363795232043\n",
      "physical_device_desc: \"device: 1, name: Tesla K80, pci bus id: 0000:88:00.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5, 6\"\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(box_a, box_b):\n",
    "    x_overlap = max(0, min(box_a[2], box_b[2]) - max(box_a[0], box_b[0]))\n",
    "    y_overlap = max(0, min(box_a[3], box_b[3]) - max(box_a[1], box_b[1]))\n",
    "    intersection = x_overlap * y_overlap\n",
    "\n",
    "    area_box_a = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])\n",
    "    area_box_b = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])\n",
    "    union = area_box_a + area_box_b - intersection\n",
    "\n",
    "    iou = intersection / union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_hook(feature_map, hook_id):\n",
    "    with tf.variable_scope(\"ssd_hook\" + hook_id):\n",
    "        confidence = slim.conv2d(feature_map, NUM_PRED_CONF, [3, 3], activation_fn=None, scope=\"conv_conf\")\n",
    "        confidence = tf.contrib.layers.flatten(confidence)\n",
    "        \n",
    "        location = slim.conv2d(feature_map, NUM_PRED_LOC, [3, 3], activation_fn=None, scope=\"conv_loc\")\n",
    "        location = tf.contrib.layers.flatten(location)\n",
    "        \n",
    "    return confidence, location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_backbone():\n",
    "    \"\"\"\n",
    "    AlexNet\n",
    "    \"\"\"\n",
    "    x = tf.placeholder(tf.float32, [None, IMG_H, IMG_W, NUM_CHANNELS], name=\"x\")\n",
    "    is_training = tf.placeholder(tf.bool, name=\"is_training\")\n",
    "\n",
    "    preds_conf = [] \n",
    "    preds_loc = []\n",
    "\n",
    "    with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm, normalizer_params={'is_training': True}, weights_regularizer=slim.l2_regularizer(scale=REG_SCALE)):\n",
    "        net = slim.conv2d(x, 64, [11, 11], 4, padding='VALID', scope='conv1')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
    "        net = slim.conv2d(net, 192, [5, 5], scope='conv2')\n",
    "\n",
    "        net_conf, net_loc = ssd_hook(net, 'conv2')\n",
    "        preds_conf.append(net_conf)\n",
    "        preds_loc.append(net_loc)\n",
    "    \n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "        net = slim.conv2d(net, 384, [3, 3], scope='conv3')\n",
    "        net = slim.conv2d(net, 384, [3, 3], scope='conv4')\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv5')\n",
    "\n",
    "        \n",
    "        net = slim.conv2d(net, 1024, [3, 3], scope='conv6')\n",
    "        net = slim.conv2d(net, 1024, [1, 1], scope='conv7')\n",
    "        net_conf, net_loc = ssd_hook(net, 'conv7')\n",
    "        \n",
    "        \n",
    "        preds_conf.append(net_conf)\n",
    "        preds_loc.append(net_loc)\n",
    "\n",
    "        \n",
    "        net = slim.conv2d(net, 256, [1, 1], scope='conv8')\n",
    "        net = slim.conv2d(net, 512, [3, 3], 2, scope='conv8_2')\n",
    "        net_conf, net_loc = ssd_hook(net, 'conv8_2')\n",
    "        \n",
    "        \n",
    "        preds_conf.append(net_conf)\n",
    "        preds_loc.append(net_loc)\n",
    "\n",
    "        \n",
    "        net = slim.conv2d(net, 128, [1, 1], scope='conv9')\n",
    "        net = slim.conv2d(net, 256, [3, 3], 2, scope='conv9_2')\n",
    "        net_conf, net_loc = ssd_hook(net, 'conv9_2')\n",
    "        \n",
    "        \n",
    "        preds_conf.append(net_conf)\n",
    "        preds_loc.append(net_loc)\n",
    "\n",
    "        \n",
    "        \n",
    "    final_pred_conf = tf.concat(preds_conf, axis=1)\n",
    "    final_pred_loc = tf.concat(preds_loc, axis=1)\n",
    "\n",
    "    # Return a dictionary of {tensor_name: tensor_reference}\n",
    "    return_dict = {'x': x,\n",
    "                   'y_pred_conf': final_pred_conf,\n",
    "                   'y_pred_loc': final_pred_loc,\n",
    "                   'is_training': is_training,\n",
    "    }\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_loss(y_pred_conf, y_pred_loc):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    y_pred_conf: [batch_size, num_feature_map_cells * num_defaul_boxes * num_classes]\n",
    "    y_pred_loc: [batch_size, num_feature_map_cells * num_defaul_boxes * 4]\n",
    "    \"\"\"\n",
    "    num_total_preds = 0\n",
    "    for fm_size in FM_SIZES:\n",
    "        num_total_preds += fm_size[0] * fm_size[1] * NUM_DEFAULT_BOXES\n",
    "        \n",
    "    num_total_preds_conf = num_total_preds * NUM_CLASSES\n",
    "    num_total_preds_loc = num_total_preds * 4\n",
    "    \n",
    "    \n",
    "    y_true_conf = tf.placeholder(tf.int32, [None, num_total_preds], name='y_true_conf')  \n",
    "    y_true_loc  = tf.placeholder(tf.float32, [None, num_total_preds_loc], name='y_true_loc')\n",
    "    conf_loss_mask = tf.placeholder(tf.float32, [None, num_total_preds], name=\"conf_loss_mask\")\n",
    "    \n",
    "    \n",
    "    # confidence loss\n",
    "    logits = tf.reshape(y_pred_conf, [-1, num_total_preds, NUM_CLASSES])\n",
    "    conf_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_true_conf)\n",
    "\n",
    "    conf_loss = conf_loss_mask * conf_loss\n",
    "    conf_loss = tf.reduce_sum(conf_loss)\n",
    "    \n",
    "    # location loss\n",
    "    diff = y_true_loc - y_pred_loc\n",
    "    \n",
    "    loc_loss_l2 = 0.5 * (diff ** 2)\n",
    "    loc_loss_l1 = tf.abs(diff) - 0.5\n",
    "    \n",
    "    smooth_l1_condition = tf.less(tf.abs(diff), 1.0)\n",
    "    loc_loss = tf.where(smooth_l1_condition, loc_loss_l2, loc_loss_l1)\n",
    "    \n",
    "    loc_loss_mask = tf.minimum(y_true_conf, 1)\n",
    "    loc_loss_mask = tf.to_float(loc_loss_mask)\n",
    "    loc_loss_mask = tf.stack([loc_loss_mask] * 4, axis=2) \n",
    "    loc_loss_mask = tf.reshape(loc_loss_mask, [-1, num_total_preds_loc])\n",
    "    loc_loss = loc_loss_mask * loc_loss\n",
    "    loc_loss = tf.reduce_sum(loc_loss)\n",
    "    \n",
    "    loss = conf_loss + LOC_LOSS_WEIGHT * loc_loss + tf.reduce_sum(slim.losses.get_regularization_losses())\n",
    "    \n",
    "    optimizer = tf.train.AdadeltaOptimizer(learning_rate=0.005).minimize(loss)    \n",
    "    \n",
    "    probs_all = tf.nn.softmax(logits)\n",
    "    probs, preds_conf = tf.nn.top_k(probs_all) \n",
    "    probs = tf.reshape(probs, [-1, num_total_preds])\n",
    "    preds_conf = tf.reshape(preds_conf, [-1, num_total_preds])\n",
    "    \n",
    "    \n",
    "    return_dict = {'y_true_conf': y_true_conf,\n",
    "                   'y_true_loc': y_true_loc,\n",
    "                   'conf_loss_mask': conf_loss_mask,\n",
    "                   'optimizer': optimizer,\n",
    "                   'conf_loss': conf_loss,\n",
    "                   'loc_loss': loc_loss,\n",
    "                   'loss': loss,\n",
    "                   'probs': probs,\n",
    "                   'preds_conf': preds_conf,\n",
    "                   'preds_loc': y_pred_loc\n",
    "    }\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_model():\n",
    "#     if MODEL == \"AlexNet\":\n",
    "#         model = \n",
    "    model = ssd_backbone()\n",
    "    loss = ssd_loss(model[\"y_pred_conf\"], model[\"y_pred_loc\"])\n",
    "    ssd_model = {}\n",
    "    for k in model.keys():\n",
    "        ssd_model[k] = model[k]\n",
    "    \n",
    "    for k in loss.keys():\n",
    "        ssd_model[k] = loss[k]\n",
    "        \n",
    "    return ssd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(y_pred_conf, y_pred_loc, prob):\n",
    "    class_boxes = {} \n",
    "    with open('signnames.csv', 'r') as f:\n",
    "        for line in f:\n",
    "            cls, _ = line.split(',')\n",
    "            class_boxes[float(cls)] = []\n",
    "\n",
    "    y_idx = 0\n",
    "    for fm_size in FM_SIZES:\n",
    "        fm_h, fm_w = fm_size\n",
    "        for row in range(fm_h):\n",
    "            for col in range(fm_w):\n",
    "                for db in DEFAULT_BOXES:\n",
    "                    # if class confidence > CONF_THRESH\n",
    "                    # and not background class\n",
    "                    if prob[y_idx] > CONF_THRESH and y_pred_conf[y_idx] > 0.:\n",
    "                        # absolute coordinates\n",
    "                        xc, yc = col + 0.5, row + 0.5\n",
    "                        center_coords = np.array([xc, yc, xc, yc])\n",
    "                        abs_box_coords = center_coords + y_pred_loc[y_idx*4 : y_idx*4 + 4] \n",
    "\n",
    "                        # box coordinates in actual image\n",
    "                        scale = np.array([IMG_W/fm_w, IMG_H/fm_h, IMG_W/fm_w, IMG_H/fm_h])\n",
    "                        box_coords = abs_box_coords * scale\n",
    "                        box_coords = [int(round(x)) for x in box_coords]\n",
    "\n",
    "                        # compare this box to all previous boxes of this class\n",
    "                        cls = y_pred_conf[y_idx]\n",
    "                        cls_prob = prob[y_idx]\n",
    "                        box = (box_coords, cls, cls_prob)\n",
    "                        if len(class_boxes[cls]) == 0:\n",
    "                            class_boxes[cls].append(box)\n",
    "                        else:\n",
    "                            suppressed = False \n",
    "                            overlapped = False \n",
    "                            for other_box in class_boxes[cls]:\n",
    "                                iou = calc_iou(box[:4], other_box[:4])\n",
    "                                if iou > NMS_IOU_THRESH:\n",
    "                                    overlapped = True\n",
    "                                    # if current box has higher confidence than other box\n",
    "                                    if box[5] > other_box[5]:\n",
    "                                        class_boxes[cls].remove(other_box)\n",
    "                                        suppressed = True\n",
    "                            \n",
    "                            if suppressed or not overlapped:\n",
    "                                class_boxes[cls].append(box)\n",
    "\n",
    "                    y_idx += 1\n",
    "\n",
    "    boxes = []\n",
    "    for cls in class_boxes.keys():\n",
    "        for class_box in class_boxes[cls]:\n",
    "            boxes.append(class_box)\n",
    "    boxes = np.array(boxes)\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hcui/anaconda3/envs/hcui/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/hcui/anaconda3/envs/hcui/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from config import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y_conf, y_loc, batch_size):\n",
    "    start_idx = 0\n",
    "    while True:\n",
    "        image_files = X[start_idx : start_idx + batch_size]\n",
    "        y_true_conf = np.array(y_conf[start_idx : start_idx + batch_size])\n",
    "        y_true_loc  = np.array(y_loc[start_idx : start_idx + batch_size])\n",
    "\n",
    "        # Read images from image_files\n",
    "        images = []\n",
    "        for image_file in image_files:\n",
    "            image = Image.open('%s' % (image_file))\n",
    "            image = np.asarray(image)\n",
    "            image = image[:, :, :3]\n",
    "\n",
    "            images.append(image)\n",
    "\n",
    "        \n",
    "        images = np.array(images)\n",
    "        images = images/127.5 - 1.\n",
    "        \n",
    "\n",
    "        num_pos = np.where(y_true_conf > 0)[0].shape[0]\n",
    "        num_neg = NEG_POS_RATIO * num_pos\n",
    "        y_true_conf_size = np.sum(y_true_conf.shape)\n",
    "\n",
    "        if num_pos + num_neg < y_true_conf_size:\n",
    "            conf_loss_mask = np.copy(y_true_conf)\n",
    "            conf_loss_mask[np.where(conf_loss_mask > 0)] = 1.\n",
    "\n",
    "            zero_indices = np.where(conf_loss_mask == 0.)  \n",
    "            zero_indices = np.transpose(zero_indices) \n",
    "\n",
    "            chosen_zero_indices = zero_indices[np.random.choice(zero_indices.shape[0], int(num_neg), False)]\n",
    "\n",
    "            for zero_idx in chosen_zero_indices:\n",
    "                i, j = zero_idx\n",
    "                conf_loss_mask[i][j] = 1.\n",
    "\n",
    "        else:\n",
    "            conf_loss_mask = np.ones_like(y_true_conf)\n",
    "\n",
    "        yield images, y_true_conf, y_true_loc, conf_loss_mask\n",
    "\n",
    "        start_idx += batch_size\n",
    "        if start_idx >= X.shape[0]:\n",
    "            start_idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-056f902bf37f>:43: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n",
      "Training model from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [02:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Train loss: 18.9276, Validation loss: 18.8708, Elapsed time: 127.19 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:55<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -- Train loss: 18.8147, Validation loss: 18.7565, Elapsed time: 120.65 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 14/71 [00:23<01:35,  1.67s/it]"
     ]
    }
   ],
   "source": [
    "# def train():\n",
    "with open('data_prep_%sx%s.p' % (IMG_W, IMG_H), mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "X_train = []    \n",
    "y_train_conf = []\n",
    "y_train_loc = []\n",
    "\n",
    "for image_file in train.keys():\n",
    "#     print(image_file)\n",
    "    X_train.append(image_file)\n",
    "    y_train_conf.append(train[image_file][\"y_true_conf\"])\n",
    "    y_train_loc.append(train[image_file][\"y_true_loc\"])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train_conf = np.array(y_train_conf)\n",
    "y_train_loc = np.array(y_train_loc)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train_conf, y_valid_conf, y_train_loc, y_valid_loc = train_test_split(X_train, y_train_conf, y_train_loc, test_size=VALIDATION_SIZE, random_state=1)\n",
    "\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    model = ssd_model()\n",
    "    x = model['x']\n",
    "    y_true_conf = model['y_true_conf']\n",
    "    y_true_loc = model['y_true_loc']\n",
    "    conf_loss_mask = model['conf_loss_mask']\n",
    "    is_training = model['is_training']\n",
    "    optimizer = model['optimizer']\n",
    "    reported_loss = model['loss']\n",
    "\n",
    "    # Training process\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    if RESUME:\n",
    "        print('Restoring previously trained model at %s' % MODEL_SAVE_PATH)\n",
    "        saver.restore(sess, MODEL_SAVE_PATH)\n",
    "\n",
    "        with open('loss_history.p', 'rb') as f:\n",
    "            loss_history = pickle.load(f)\n",
    "    else:\n",
    "        print('Training model from scratch')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        loss_history = []\n",
    "\n",
    "    last_time = time.time()\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        \n",
    "        train_gen = batch_generator(X_train, y_train_conf, y_train_loc, BATCH_SIZE)\n",
    "        num_batches_train = math.ceil(X_train.shape[0] / BATCH_SIZE)\n",
    "        losses = []  \n",
    "\n",
    "        for i in tqdm(range(num_batches_train)):\n",
    "            \n",
    "            images, y_true_conf_gen, y_true_loc_gen, conf_loss_mask_gen = next(train_gen)\n",
    "            \n",
    "            if images.shape != (BATCH_SIZE, 300, 400, 3):\n",
    "                continue\n",
    "#             print(images.shape, y_true_conf_gen.shape, y_true_loc_gen.shape, conf_loss_mask_gen.shape)\n",
    "            _, loss = sess.run([optimizer, reported_loss], feed_dict={\n",
    "                x: images,\n",
    "                y_true_conf: y_true_conf_gen,\n",
    "                y_true_loc: y_true_loc_gen,\n",
    "                conf_loss_mask: conf_loss_mask_gen,\n",
    "                is_training: True\n",
    "            })\n",
    "            \n",
    "            losses.append(loss)  \n",
    "\n",
    "        train_loss = np.mean(losses)\n",
    "\n",
    "        valid_gen = batch_generator(X_valid, y_valid_conf, y_valid_loc, BATCH_SIZE)\n",
    "        num_batches_valid = math.ceil(X_valid.shape[0] / BATCH_SIZE)\n",
    "        losses = []\n",
    "        \n",
    "        for _ in range(num_batches_valid):\n",
    "            images, y_true_conf_gen, y_true_loc_gen, conf_loss_mask_gen = next(valid_gen)\n",
    "\n",
    "            loss = sess.run(reported_loss, feed_dict={\n",
    "                x: images,\n",
    "                y_true_conf: y_true_conf_gen,\n",
    "                y_true_loc: y_true_loc_gen,\n",
    "                conf_loss_mask: conf_loss_mask_gen,\n",
    "                is_training: False\n",
    "            })\n",
    "            losses.append(loss)\n",
    "        valid_loss = np.mean(losses)\n",
    "\n",
    "        loss_history.append((train_loss, valid_loss))\n",
    "\n",
    "        print('Epoch %d -- Train loss: %.4f, Validation loss: %.4f, Elapsed time: %.2f sec' % (epoch+1, train_loss, valid_loss, time.time() - last_time))\n",
    "        last_time = time.time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, MODEL_SAVE_PATH, global_step=epoch+1)\n",
    "\n",
    "\n",
    "    total_time = time.time() - train_start_time\n",
    "    print('Total elapsed time: %d min %d sec' % (total_time/60, total_time%60))\n",
    "\n",
    "    if SAVE_MODEL:\n",
    "        save_path = saver.save(sess, MODEL_SAVE_PATH)\n",
    "        with open('loss_history.p', 'wb') as f:\n",
    "            pickle.dump(loss_history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from config import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from optparse import OptionParser\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image, model, sess, mode, sign_map):\n",
    "\n",
    "    image = np.array(image)\n",
    "    image_orig = np.copy(image)\n",
    "\n",
    "    x = model['x']\n",
    "    is_training = model['is_training']\n",
    "    preds_conf = model['preds_conf']\n",
    "    preds_loc = model['preds_loc']\n",
    "    probs = model['probs']\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    orig_w, orig_h = image.size\n",
    "\n",
    "    image = image.resize((IMG_W, IMG_H), Image.LANCZOS)  \n",
    "    image = np.asarray(image)\n",
    "\n",
    "    images = np.array([image])  \n",
    "\n",
    "    t0 = time.time()  \n",
    "    preds_conf_val, preds_loc_val, probs_val = sess.run([preds_conf, preds_loc, probs], feed_dict={x: images, is_training: False})\n",
    "\n",
    "    print('Inference took %.1f ms (%.2f fps)' % ((time.time() - t0)*1000, 1/(time.time() - t0)))\n",
    "\n",
    "    y_pred_conf = preds_conf_val[0]  \n",
    "    y_pred_conf = y_pred_conf.astype('float32')\n",
    "    prob = probs_val[0]\n",
    "\n",
    "    y_pred_loc = preds_loc_val[0]\n",
    "\n",
    "    boxes = nms(y_pred_conf, y_pred_loc, prob)\n",
    "    print('Inference + NMS took %.1f ms (%.2f fps)' % ((time.time() - t0)*1000, 1/(time.time() - t0)))\n",
    "\n",
    "    # rescale box back to image\n",
    "    scale = np.array([orig_w/IMG_W, orig_h/IMG_H, orig_w/IMG_W, orig_h/IMG_H])\n",
    "    if len(boxes) > 0:\n",
    "        boxes[:, :4] = boxes[:, :4] * scale\n",
    "\n",
    "    # draw box\n",
    "    image = image_orig\n",
    "    for box in boxes:\n",
    "        box_coords = [int(round(x)) for x in box[:4]]\n",
    "        cls = int(box[4])\n",
    "        cls_prob = box[5]\n",
    "\n",
    "        image = cv2.rectangle(image, tuple(box_coords[:2]), tuple(box_coords[2:]), (0,255,0))\n",
    "        label_str = '%s %.2f' % (sign_map[cls], cls_prob)\n",
    "        image = cv2.putText(image, label_str, (box_coords[0], box_coords[1]), 0, 0.5, (0,255,0), 1, cv2.LINE_AA)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(input_files):\n",
    "    \"\"\"\n",
    "    Generate annotated images, videos, or sample images, based on mode\n",
    "    \"\"\"\n",
    "    # First, load mapping from integer class ID to sign name string\n",
    "    sign_map = {}\n",
    "    \n",
    "    sign_map[0] = \"background\"  # class ID 0 reserved for background class\n",
    "    sign_map[1] = \"pedestrian\"\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        # \"Instantiate\" neural network, get relevant tensors\n",
    "        model = ssd_model()\n",
    "\n",
    "        saver.restore(sess, MODEL_SAVE_PATH)\n",
    "\n",
    "        for image_file in input_files:\n",
    "            print('Running inference on %s' % image_file)\n",
    "            image_orig = np.asarray(Image.open(image_file))\n",
    "            image = inference(image_orig, model, sess, mode, sign_map)\n",
    "\n",
    "            head, tail = os.path.split(image_file)\n",
    "            \n",
    "            plt.imsave('./inference/%s' % tail, image)\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hcui]",
   "language": "python",
   "name": "conda-env-hcui-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
